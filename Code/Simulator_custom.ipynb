{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Simulator (custom)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to create synthetic twitter datasets according to the model. We create a user graph and choose an activity pair $(\\lambda,\\mu)$ for each user . From there we can generate events of tweeting/retweeting where each user $i$ tweets with rate $\\lambda_i$ and retweets from his newsfeed with rate $\\mu_i$. The output consists of two `.txt` files, one being the adjacency list of the user graph and the other the list of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import choice\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose out folder where the results will be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = \"../Datasets/Newman/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters\n",
    "Choose the number of users $N$, the number of events `nb_events` and the activity rates. The latter are in the form of two lists of length $N$: `Lambda` and `Mu` where `Lambda[i]` is the posting rate of user $i$ and `Mu[i]` is her reposting rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "w = 0.1\n",
    "nb_events = 40*w*N*(N-1)\n",
    "\n",
    "# Lambda = np.random.pareto(1.3, N)\n",
    "# Mu = np.random.pareto(1.3, N)\n",
    "\n",
    "Lambda = [0.1 for n in range(N)]\n",
    "Mu = [0.1 for n in range(N)]\n",
    "\n",
    "# Lambda = np.random.random(N)\n",
    "# Mu = np.random.random(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User graph creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent the user graph with a dictionary `Followers` where `Followers[i]` is the set of leaders of user $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  951\n"
     ]
    }
   ],
   "source": [
    "# example: graph Erdös-Rényi of parameter w\n",
    "Followers = {i:set() for i in range(N)}\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j != i and np.random.random() < w:\n",
    "            Followers[i].add(j)\n",
    "print(\"Number of edges: \", sum([len(Followers[i]) for i in range(N)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write adjacency list on file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_out = open(out_folder + \"adjList_scaleTest.txt\", \"w\")\n",
    "for i in Followers:\n",
    "    for j in Followers[i]:\n",
    "        graph_out.write(\"{} {}\\n\".format(i,j))\n",
    "graph_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Events creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a list `events` where the $i^{th}$ entry corresponds to the $i^{th}$ event occurring on the network. Each event is described as a tuple `twid timestamp userid rtid`, with\n",
    "- `twid` is the unique id of the tweet, $\\in \\{1, \\ldots, nb\\_events\\}$\n",
    "- `timestamp` is the instant of occurence (seconds since the beginning)\n",
    "- `userid` is the unique id $\\in \\{1, \\ldots, N\\}$ of the (re)tweeting user\n",
    "- `rtid` is the id of the original tweet in case of retweet, else is set to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = {i:list() for i in range(N)} # initialization of the newsfeeds\n",
    "M = 1 # newsfeeds max size\n",
    "next_twid = 1 # id of the next post\n",
    "time = 0 # time since the beginning\n",
    "Events = list() # list of events (output)\n",
    "\n",
    "while len(Events) < nb_events:\n",
    "    \n",
    "    # generate exponential variates of scale 1/lambda, 1/mu for each user\n",
    "    posting_time = np.random.exponential([1/x for x in Lambda], N)\n",
    "    reposting_time = np.random.exponential([1/x for x in Mu], N)\n",
    "    \n",
    "    # get closest posting time and reposting time ---> next event will be the closest between both\n",
    "    min_post = np.min(posting_time)\n",
    "    min_repost = np.min(reposting_time)\n",
    "    \n",
    "    # if the next event is a post\n",
    "    if min_post < min_repost:\n",
    "        time += min_post\n",
    "        user = np.argmin(posting_time)\n",
    "        new_post = (next_twid, time, user, -1) # create new post\n",
    "    \n",
    "    # if repost\n",
    "    elif min_repost < min_post:\n",
    "        time += min_repost\n",
    "        user = np.argmin(reposting_time)\n",
    "        if len(news[user]) == 0: # skip step if nothing to repost in the user's newsfeed\n",
    "            continue\n",
    "        else:\n",
    "            retweeted = choice(news[user]) # choose what to retweet\n",
    "            if retweeted[-1] == -1: # get original id\n",
    "                rtid = retweeted[0]\n",
    "            else:\n",
    "                rtid = retweeted[-1]\n",
    "            new_post = (next_twid, time, user, rtid) # create new_post\n",
    "            \n",
    "            \n",
    "    # append new post to the events list and update next_twid\n",
    "    Events.append(new_post)\n",
    "    next_twid += 1\n",
    "\n",
    "    # update newfeeds for followers of active user\n",
    "    for j in Followers[user]:\n",
    "        if len(news[j]) == M: # remove something at random if newsfeed is full\n",
    "            news[j].remove(choice(news[j]))\n",
    "        news[j].append(new_post) # add new post to newsfeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.19810903208170605, 50, -1),\n",
       " (2, 0.7140163339160908, 65, -1),\n",
       " (3, 0.8047981023603267, 50, 2),\n",
       " (4, 0.8853206869417127, 44, -1),\n",
       " (5, 0.9624986267202988, 56, 2),\n",
       " (6, 0.9751831801809541, 47, -1),\n",
       " (7, 1.0221095076712632, 79, -1),\n",
       " (8, 1.0474477197348255, 12, 7),\n",
       " (9, 1.1348709504679284, 41, -1),\n",
       " (10, 1.1472306672544499, 90, 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Events[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write events list to `outfolder/trace.txt`. Each line is an entry of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(out_folder + \"trace_scaleTest.txt\", \"w\")\n",
    "for e in Events:\n",
    "    out.write(\"{} {} {} {}\\n\".format(e[0], e[1], e[2], e[3]))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
