{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Simulator </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to create synthetic twitter datasets according to the model. We create a user graph and choose an activity pair $(\\lambda,\\mu)$ for each user . From there we can generate events of tweeting/retweeting where each user $i$ tweets with rate $\\lambda_i$ and retweets from his newsfeed with rate $\\mu_i$. The output consists of two `.txt` files, one being the adjacency list of the user graph and the other the list of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as random\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose out folder where the results will be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters\n",
    "Choose the number of users $N$, the number of events `nb_events` and the activity rates. The latter are in the form of two lists of length $N$: `Lambda` and `Mu` where `Lambda[i]` is the posting rate of user $i$ and `Mu[i]` is her reposting rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "nb_events = 10000\n",
    "\n",
    "Lambda = np.random.random(N)\n",
    "Mu = np.random.random(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User graph creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent the user graph with a dictionary `Followers` where `Followers[i]` is the set of leaders of user $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  230\n"
     ]
    }
   ],
   "source": [
    "# example: graph Erdös-Rényi of parameter w\n",
    "w = 0.1\n",
    "Followers = {i:set() for i in range(N)}\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if j != i and np.random.random() < w:\n",
    "            Followers[i].add(j)\n",
    "print(\"Number of edges: \", sum([len(Followers[i]) for i in range(N)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write adjacency list on file `out_folder/adjList.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_out = open(out_folder + \"adjList.txt\", \"w\")\n",
    "for i in Followers:\n",
    "    for j in Followers[i]:\n",
    "        graph_out.write(\"{} {}\\n\".format(i,j))\n",
    "graph_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Timestamps creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is to create a list of the events that will occurr on the network, each entry being of the form `userid timestamp event_type`, with\n",
    "- `userid` is the unique id $\\in \\{1, \\ldots, N\\}$ of the (re)tweeting user\n",
    "- `timestamp` is the instant of occurence (seconds since the beginning)\n",
    "- `event_type` is a string that indicates if the event is an original post ('post') or a repost ('repost').\n",
    "\n",
    "There are 3 functions:\n",
    "- `exponential_timestamps` creates events with exponential inter-arrival times, i.e. the activity of any user follows a Poisson process\n",
    "- `hyperexp_timestamps` creates events with hyper-exponential inter-arrival times\n",
    "- `constant_timestamps` creates events with constant inter-arrival times.\n",
    "\n",
    "For each one, a maximal number of events must be precised to control the size of the output list. Events are generated user by user, first posts then reposts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exponential timestamps\n",
    "Waiting time between two posts (resp. reposts) from user $i$ is distributed with the density $\\lambda_i e^{-\\lambda_i x}$ (resp. $\\mu_i e^{-\\mu_i x}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_timestamps(lambdas, mus, nb_events):\n",
    "    \n",
    "    # init\n",
    "    N = len(lambdas)\n",
    "    events = list()\n",
    "    \n",
    "    # generate user by user\n",
    "    for j in range(N):\n",
    "        lambd, mu = lambdas[j], mus[j]\n",
    "        \n",
    "        # first posts\n",
    "        if lambd > 0:\n",
    "            time = 0\n",
    "            for n in range(nb_events):\n",
    "                dice = random.expovariate(lambdas[j])\n",
    "                time += dice\n",
    "                events.append((j, time, 'post'))\n",
    "            \n",
    "        # then reposts\n",
    "        if mu > 0:\n",
    "            time = 0\n",
    "            for n in range(nb_events):\n",
    "                dice = random.expovariate(mus[j])\n",
    "                time += dice\n",
    "                events.append((j, time, 'repost'))\n",
    "        \n",
    "    # end\n",
    "    return sorted(events, key=itemgetter(1))[:nb_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Hyper-exponential timestamps\n",
    "Waiting time before the next post from user $i$ is distributed as follows:\n",
    "- with proba $p_i$ it is exponential of parameter $\\lambda_i^{(1)}$\n",
    "- with proba $1 - p_i$ it is exponential of parameter $\\lambda_i^{(2)}$\n",
    "\n",
    "Note that if we set $p_i=10/11$, $\\lambda_i^{(1)} = 10 \\lambda_i$ and $\\lambda_i^{(2)} = 0.1 \\lambda_i$ then the inter-arrival times have the same mean that if we used exponential distribution of parameter $\\lambda_i$.\n",
    "\n",
    "Behavior for reposts is similar, with $q$ instead of $p$.\n",
    "\n",
    "<b> Warning! </b> If $\\lambda_i^{(1)} > 0$ we require $\\lambda_i^{(2)} > 0$ and reversely. Same for $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperexp_timestamps(lambdas1, lambdas2, mus1, mus2, p, q, nb_events):\n",
    "    \n",
    "    # init\n",
    "    N = len(lambdas1)\n",
    "    events = list()\n",
    "    \n",
    "    # generate user by user\n",
    "    for j in range(N):\n",
    "        p, q, lambd1, lambd2, mu1, mu2 = p[j], q[j], lambdas1[j], lambdas2[j], mus1[j], mus2[j]\n",
    "        \n",
    "        # first posts\n",
    "        if lambd1 > 0:\n",
    "            time = 0\n",
    "            for n in range(nb_events):\n",
    "                dice = random.random()\n",
    "                if dice < p:\n",
    "                    time += random.expovariate(lambd1)\n",
    "                else:\n",
    "                    time += random.expovariate(lambd2)\n",
    "                events.append((n, time, 'post')\n",
    "            \n",
    "        # then reposts\n",
    "        if mu1 > 0:\n",
    "            time = 0\n",
    "            for n in range(nb_events):\n",
    "                dice = random.random()\n",
    "                if dice < q:\n",
    "                    time += random.expovariate(mu1)\n",
    "                else:\n",
    "                    time += random.expovariate(mu2)\n",
    "                events.append((n, time, 'repost'))\n",
    "        \n",
    "    # end\n",
    "    return sorted(events, key=itemgetter(1))[:nb_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Constant timestamps\n",
    "Here we just have to choose an inter-arrival time for each user and it will always be the same. `inter_post` is the list of inter-posting times and `inter_repost` the list of inter-reposting times. Setting one of those to zero makes the user never take the corresponding action (post or repost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_timestamps(inter_post, inter_repost nb_events):\n",
    "    \n",
    "    # init\n",
    "    N = len(inter_post)\n",
    "    events = list()\n",
    "    \n",
    "    # generate user by user\n",
    "    for j in range(N):\n",
    "        t,s = inter_post[j], inter_repost[j]\n",
    "        \n",
    "        # first posts\n",
    "        if t > 0:\n",
    "            time = 0\n",
    "            for n in range(nb_events):\n",
    "                time += t\n",
    "                events.append((j, time, 'post'))\n",
    "            \n",
    "        # then reposts\n",
    "        if s > 0:\n",
    "            time = 0\n",
    "            for n in range(nb_events):\n",
    "                time += s\n",
    "                events.append((j, time, 'repost'))\n",
    "        \n",
    "    # end\n",
    "    return sorted(events, key=itemgetter(1))[:nb_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a list `Events` where the $i^{th}$ entry corresponds to the $i^{th}$ event occurring on the network. Each event is described as a tuple `twid timestamp userid rtid`, with\n",
    "- `twid` is the unique id of the tweet, $\\in \\{1, \\ldots, nb\\_events\\}$\n",
    "- `timestamp` is the instant of occurence (seconds since the beginning)\n",
    "- `userid` is the unique id $\\in \\{1, \\ldots, N\\}$ of the (re)tweeting user\n",
    "- `rtid` is the id of the original tweet in case of retweet, else is set to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = {i:list() for i in range(N)} # initialization of the newsfeeds\n",
    "M = 1 # newsfeeds max size\n",
    "next_twid = 1 # id of the next post\n",
    "time = 0 # time since the beginning\n",
    "Events = list() # list of events (output)\n",
    "\n",
    "while len(Events) < nb_events:\n",
    "    \n",
    "    # generate exponential variates of scale 1/lambda, 1/mu for each user\n",
    "    posting_time = np.random.exponential([1/x for x in Lambda], N)\n",
    "    reposting_time = np.random.exponential([1/x for x in Mu], N)\n",
    "    \n",
    "    # get closest posting time and reposting time ---> next event will be the closest between both\n",
    "    min_post = np.min(posting_time)\n",
    "    min_repost = np.min(reposting_time)\n",
    "    \n",
    "    # if the next event is a post\n",
    "    if min_post < min_repost:\n",
    "        time += min_post\n",
    "        user = np.argmin(posting_time)\n",
    "        new_post = (next_twid, time, user, -1) # create new post\n",
    "    \n",
    "    # if repost\n",
    "    if min_repost < min_post:\n",
    "        time += min_repost\n",
    "        user = np.argmin(reposting_time)\n",
    "        if len(news[user]) == 0: # skip step if nothing to repost in the user's newsfeed\n",
    "            continue\n",
    "        else:\n",
    "            retweeted = choice(news[user]) # choose what to retweet\n",
    "            if retweeted[-1] == -1: # get original id\n",
    "                rtid = retweeted[0]\n",
    "            else:\n",
    "                rtid = retweeted[-1]\n",
    "            new_post = (next_twid, time, user, rtid) # create new_post\n",
    "            \n",
    "            \n",
    "    # append new post to the events list and update next_twid\n",
    "    Events.append(new_post)\n",
    "    next_twid += 1\n",
    "\n",
    "    # update newfeeds for followers of active user\n",
    "    for j in Followers[user]:\n",
    "        if len(news[j]) == M: # remove something at random if newsfeed is full\n",
    "            news[j].remove(choice(news[j]))\n",
    "        news[j].append(new_post) # add new post to newsfeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.019944872312488128, 2, -1),\n",
       " (2, 0.06049742454360553, 28, -1),\n",
       " (3, 0.07310548686901136, 36, -1),\n",
       " (4, 0.12442863488915959, 28, -1),\n",
       " (5, 0.12514990876846757, 41, -1),\n",
       " (6, 0.13585355226380755, 41, 1),\n",
       " (7, 0.13700234596857155, 20, 3),\n",
       " (8, 0.14718610545218702, 28, -1),\n",
       " (9, 0.18037391661276286, 45, -1),\n",
       " (10, 0.18128343169803307, 47, -1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Events[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write events list to `outfolder/trace.txt`. Each line is an entry of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(out_folder + \"trace.txt\", \"w\")\n",
    "for e in Events:\n",
    "    out.write(\"{} {} {} {}\\n\".format(e[0], e[1], e[2], e[3]))\n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
